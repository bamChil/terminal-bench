import torch.nn as nn

from liger_kernel.ops.geglu import LigerGELUMulFunction


class LigerGEGLUMLP(nn.Module):

    def __init__(self, config):
        raise NotImplementedError('This function has been masked for testing')

    def forward(self, x):
        raise NotImplementedError('This function has been masked for testing')